{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b880e37",
   "metadata": {},
   "source": [
    "# Fraud Detection with Amazon SageMaker - XGBoost\n",
    "\n",
    "*Supervised Learning with Gradient Boosted Trees: Binary Prediction with unbalanced classes.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fff7af",
   "metadata": {},
   "source": [
    "## Background \n",
    "\n",
    "Globally each year, tens of billions of dollars are lost to online fraud. To prevent fraud, companies need to \n",
    "develop machine learning powered fraud detection applications, as the traditional rule based solutions cannot cope up \n",
    "with the changing behaviour of the fraudsters. In this notebook, we will see how you can build, train, tune and deploy a fraud detection model with Amazon SageMaker. \n",
    "\n",
    "Steps include: \n",
    "- Preparing your Amazon SageMaker notebook \n",
    "- Downloading the data from the internet into Amazon SageMaker \n",
    "- Investigating and transforming the data so that it can be fed into Amazon SageMaker Algorithms. \n",
    "- Estimating a model using the Gradient Boosting algorithm.\n",
    "- Evaluating effectiveness of the model\n",
    "- Setting the model up to make on-going predictions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9e757",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "*This notebook was creted and tested on am ml.m4.xlarge notebook instance.* \n",
    "\n",
    "Specifications: \n",
    "- S3 Bucket prefix that is required for training and model data. \n",
    "- IAM Role arn used to give training and hosting access to the data. Documentation can be referred in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31bf141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (1.3.4)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.4\n",
      "    Uninstalling pandas-1.3.4:\n",
      "      Successfully uninstalled pandas-1.3.4\n",
      "Successfully installed pandas-1.4.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a1ba464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/DEMO-xgboost-fraud'\n",
    "\n",
    "import boto3 \n",
    "import re \n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff93c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the required python libraries are imported. \n",
    "\n",
    "# Matrix operations and numerical processing. \n",
    "import numpy as np \n",
    "\n",
    "# Munging tabular data. \n",
    "import pandas as pd \n",
    "\n",
    "# For visualizations and charts. \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# To display images in the notebook. \n",
    "from IPython.display import Image \n",
    "\n",
    "# To display outputs in the notebook. \n",
    "from IPython.display import display \n",
    "\n",
    "# Labelling sagemaker models, endpoints, etc. \n",
    "from time import gmtime, strftime \n",
    "\n",
    "# For writing outputs to notebook \n",
    "import sys \n",
    "\n",
    "# For ceiling functions\n",
    "import math \n",
    "\n",
    "# For parsing hosting outputs\n",
    "import json \n",
    "\n",
    "# Manipulating filepath names\n",
    "import os \n",
    "import sagemaker\n",
    "\n",
    "#Sagemaker's Python SDK help functions. \n",
    "import zipfile \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd22552e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104f95a",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "The credit card fraud dataset is downloaded and read: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63230161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-05 03:54:31--  https://s3-us-west-2.amazonaws.com/sagemaker-e2e-solutions/fraud-detection/creditcardfraud.zip\n",
      "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.229.152\n",
      "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.229.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 69155632 (66M) [application/zip]\n",
      "Saving to: ‘creditcardfraud.zip.2’\n",
      "\n",
      "100%[======================================>] 69,155,632  13.5MB/s   in 5.9s   \n",
      "\n",
      "2022-08-05 03:54:37 (11.2 MB/s) - ‘creditcardfraud.zip.2’ saved [69155632/69155632]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-us-west-2.amazonaws.com/sagemaker-e2e-solutions/fraud-detection/creditcardfraud.zip \n",
    "    \n",
    "with zipfile.ZipFile('creditcardfraud.zip', 'r') as zip_ref: \n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa2e590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
       "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
       "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
       "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
       "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
       "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
       "5   2.0 -0.425966  0.960523  1.141109  ...  0.253844  0.081080    3.67      0\n",
       "6   4.0  1.229658  0.141004  0.045371  ...  0.034507  0.005168    4.99      0\n",
       "7   7.0 -0.644269  1.417964  1.074380  ... -1.206921 -1.085339   40.80      0\n",
       "8   7.0 -0.894286  0.286157 -0.113192  ...  0.011747  0.142404   93.20      0\n",
       "9   9.0 -0.338262  1.119593  1.044367  ...  0.246219  0.083076    3.68      0\n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./creditcard.csv')\n",
    "print(data.columns)\n",
    "data[['Time', 'V1', 'V2', 'V27', 'V28', 'Amount', 'Class']].describe()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846b710",
   "metadata": {},
   "source": [
    "The class column refers to whether transactions are fraudulent or not. \n",
    "\n",
    "We can see that the majority of the data is non-fraudulent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e8b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frauds 492\n",
      "Number of non-frauds 284315\n",
      "Percentage of fradulent data =  0.1727485630620034\n"
     ]
    }
   ],
   "source": [
    "nonfrauds, frauds = data.groupby('Class').size()\n",
    "print('Number of frauds', frauds)\n",
    "print('Number of non-frauds', nonfrauds)\n",
    "print('Percentage of fradulent data = ', 100.*frauds/(frauds + nonfrauds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c281f7",
   "metadata": {},
   "source": [
    "This dataset has 29 columns, $V_i$ for i = 1, 2, ....., 28of anonymized features along with columns for time, amount, and class. We already know that the columns $V_i$ have been *normalized* to have 0 mean and unit standard deviation as the result of PCA (Principal Component Analysis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe99d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = data.columns[:-1]\n",
    "label_column = data.columns[-1]\n",
    "\n",
    "\n",
    "features = data[feature_columns].values.astype('float32')\n",
    "labels = data[label_column].values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5151c5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Time        V1        V2  ...       V26       V27       V28  Amount\n",
       "0      0   0.0 -1.359807 -0.072781  ... -0.189115  0.133558 -0.021053  149.62\n",
       "1      0   0.0  1.191857  0.266151  ...  0.125895 -0.008983  0.014724    2.69\n",
       "2      0   1.0 -1.358354 -1.340163  ... -0.139097 -0.055353 -0.059752  378.66\n",
       "3      0   1.0 -0.966272 -0.185226  ... -0.221929  0.062723  0.061458  123.50\n",
       "4      0   2.0 -1.158233  0.877737  ...  0.502292  0.219422  0.215153   69.99\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = data \n",
    "model_data.head()\n",
    "model_data = pd.concat([model_data['Class'], model_data.drop(['Class'], axis = 1)], axis = 1)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b8434cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation sets. \n",
    "\n",
    "\n",
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state = 123), \n",
    "                                                 [int(0.7*len(model_data)), int(0.9*len(model_data))])\n",
    "\n",
    "train_data.to_csv('train.csv', header = False, index = False)\n",
    "validation_data.to_csv('validation.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833481a4",
   "metadata": {},
   "source": [
    "# Uploading data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "186ecbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded Training data location s3://sagemaker-ap-southeast-2-789833638223/sagemaker/DEMO-xgboost-fraud/train/train.csv\n",
      "\n",
      "Uploaded Validation data location s3://sagemaker-ap-southeast-2-789833638223/sagemaker/DEMO-xgboost-fraud/validation/validation.csv\n",
      "\n",
      "Training artifacts will be uploaded to: s3://sagemaker-ap-southeast-2-789833638223/sagemaker/DEMO-xgboost-fraud/output\n"
     ]
    }
   ],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "\n",
    "s3_train_data = 's3://{}/{}/train/train.csv'.format(bucket, prefix)\n",
    "s3_validation_data = 's3://{}/{}/validation/validation.csv'.format(bucket, prefix)\n",
    "print('Uploaded Training data location {}\\n'.format(s3_train_data))\n",
    "print('Uploaded Validation data location {}\\n'.format(s3_validation_data))\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85689f7",
   "metadata": {},
   "source": [
    "## Training \n",
    "\n",
    "In the case of training, first it is necessary to specify the locations of the XGBoost Algorithm contiainers. \n",
    "To specify the linear learner algorithm, we make use of a untility function to obtain it's URI. \n",
    "\n",
    "*xgboost* is a popular open-source package for gradient boosted trees. It is computationally powerful, fully featured, and has been successfully used in many machine learning use-cases. \n",
    "\n",
    "\n",
    "The ECR Container lcoation for SageMaker's Implementation of XGBoost has to be specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2df2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(region = boto3.Session().region_name, framework = 'xgboost', version = 'latest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4dd9a7",
   "metadata": {},
   "source": [
    "Since the training data is in the CSV format, the s3_input is created can used as a pointer to the files in S3, \n",
    "which specify the content type is CSV> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6da6d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data = 's3://{}/{}/train'.format(bucket, prefix), content_type = 'csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data = 's3://{}/{}/validation/'.format(bucket, prefix), content_type = 'csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e282728",
   "metadata": {},
   "source": [
    "Training parameters have to be specified to the estimator, which includes: \n",
    "- xgboost algorithm container \n",
    "- IAM Role that has to be used \n",
    "- Training instance type and count \n",
    "- S3 location for the output data \n",
    "- Algorithm hyper parameters. \n",
    "\n",
    "\n",
    "the .fit() function specified the S3 location for output data, in which the training and validation set are passed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e344bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-05 05:30:19 Starting - Starting the training job...\n",
      "2022-08-05 05:30:43 Starting - Preparing the instances for trainingProfilerReport-1659677419: InProgress\n",
      ".........\n",
      "2022-08-05 05:32:05 Downloading - Downloading input data......\n",
      "2022-08-05 05:33:03 Training - Downloading the training image.....\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-08-05:05:33:55:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-08-05:05:33:55:INFO] File size need to be processed in the node: 129.45mb. Available memory size in the node: 8461.95mb\u001b[0m\n",
      "\u001b[34m[2022-08-05:05:33:55:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[05:33:55] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[05:33:55] 199364x30 matrix with 5980920 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2022-08-05:05:33:55:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[05:33:55] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[05:33:55] 56962x30 matrix with 1708860 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[05:33:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.000662#011validation-error:0.00065\u001b[0m\n",
      "\u001b[34m[05:33:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.000512#011validation-error:0.000702\u001b[0m\n",
      "\u001b[34m[05:33:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.000507#011validation-error:0.000597\u001b[0m\n",
      "\u001b[34m[05:33:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.000487#011validation-error:0.000614\u001b[0m\n",
      "\u001b[34m[05:33:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.000487#011validation-error:0.000597\u001b[0m\n",
      "\u001b[34m[05:33:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.000477#011validation-error:0.000562\u001b[0m\n",
      "\u001b[34m[05:33:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.000446#011validation-error:0.000562\u001b[0m\n",
      "\u001b[34m[05:33:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.000456#011validation-error:0.000527\u001b[0m\n",
      "\u001b[34m[05:34:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.000431#011validation-error:0.000527\u001b[0m\n",
      "\u001b[34m[05:34:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.000421#011validation-error:0.000509\u001b[0m\n",
      "\u001b[34m[05:34:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.000431#011validation-error:0.000527\u001b[0m\n",
      "\u001b[34m[05:34:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.000421#011validation-error:0.000527\u001b[0m\n",
      "\u001b[34m[05:34:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.000426#011validation-error:0.000544\u001b[0m\n",
      "\u001b[34m[05:34:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.000406#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.000396#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.000396#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.000416#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.000416#011validation-error:0.000509\u001b[0m\n",
      "\u001b[34m[05:34:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.000396#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.000391#011validation-error:0.000492\u001b[0m\n",
      "\n",
      "2022-08-05 05:34:04 Training - Training image download completed. Training in progress.\u001b[34m[05:34:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.000396#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.000386#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.000381#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.000371#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.000371#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.000376#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.000386#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.000376#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.000381#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.000356#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.000351#011validation-error:0.000509\u001b[0m\n",
      "\u001b[34m[05:34:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.000361#011validation-error:0.000509\u001b[0m\n",
      "\u001b[34m[05:34:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.000351#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.000356#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.000351#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.000351#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.000356#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.000351#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.000346#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.000366#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.000361#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.000366#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.000371#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.000351#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.000356#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.000361#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.000356#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.000351#011validation-error:0.000439\u001b[0m\n",
      "\u001b[34m[05:34:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.000336#011validation-error:0.000439\u001b[0m\n",
      "\u001b[34m[05:34:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.000321#011validation-error:0.000439\u001b[0m\n",
      "\u001b[34m[05:34:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.000316#011validation-error:0.000421\u001b[0m\n",
      "\u001b[34m[05:34:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.000321#011validation-error:0.000421\u001b[0m\n",
      "\u001b[34m[05:34:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.000311#011validation-error:0.000439\u001b[0m\n",
      "\u001b[34m[05:34:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.000311#011validation-error:0.000421\u001b[0m\n",
      "\u001b[34m[05:34:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.000306#011validation-error:0.000439\u001b[0m\n",
      "\u001b[34m[05:34:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.000306#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.000306#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.000306#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.000301#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.000301#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.000306#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.000301#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.000306#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 6 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.000306#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 10 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.000306#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.000301#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.000296#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.000291#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.000291#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.000296#011validation-error:0.000492\u001b[0m\n",
      "\u001b[34m[05:34:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.000296#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.000291#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.000296#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.000296#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.000296#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.000296#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.000291#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.000281#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.000286#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.000286#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.000286#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.000281#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.000276#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.000276#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.000276#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 8 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.000276#011validation-error:0.000456\u001b[0m\n",
      "\u001b[34m[05:34:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.000271#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.000271#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.000271#011validation-error:0.000474\u001b[0m\n",
      "\n",
      "2022-08-05 05:34:47 Uploading - Uploading generated training model\u001b[34m[05:34:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.000271#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.000276#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.000271#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.000266#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.000276#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.000276#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.000271#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.000266#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.000271#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.000276#011validation-error:0.000474\u001b[0m\n",
      "\u001b[34m[05:34:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.000271#011validation-error:0.000474\u001b[0m\n",
      "\n",
      "2022-08-05 05:35:04 Completed - Training job completed\n",
      "ProfilerReport-1659677419: NoIssuesFound\n",
      "Training seconds: 173\n",
      "Billable seconds: 173\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session() \n",
    "xgb = sagemaker.estimator.Estimator(container, role, instance_count = 1, instance_type = 'ml.m4.xlarge', \n",
    "                                   output_path = 's3://{}/{}/output'.format(bucket, prefix), \n",
    "                                   sagemaker_session = sess)\n",
    "\n",
    "xgb.set_hyperparameters(max_depth = 5, \n",
    "                       eta = 0.2, \n",
    "                       gamma = 4, \n",
    "                       min_child_weight = 6, \n",
    "                       subsample = 0.8, \n",
    "                       silent = 0, \n",
    "                       objective = 'binary:logistic', \n",
    "                       num_round = 100) \n",
    "                        \n",
    "                        \n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d0c24",
   "metadata": {},
   "source": [
    "### Now that the xgboost algorithm has been trained on the data, let's deploy a model that is hosted behind a real-time endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "379432df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afe48c",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "There are many ways to compare the performance of a machine learning model, but one of the simplest ways is by comparing the actual and predicted values. In this case, the prediction is made whether a transaction is fraudulent (1) or not (0). This leads to a confusion matrix. \n",
    "\n",
    "\n",
    "We need to determine how data is passed into the endpoint and how data is received from the endpoint. The data is stored as a NumPy array in memory of our notebook instance. To send it in an HTTP Post request, we'll serialize it as a CSV string and then decode the resulting CSV. \n",
    "\n",
    "\n",
    "The data should not include the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b31886f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044986ae",
   "metadata": {},
   "source": [
    "A function is used to: \n",
    "- Loop over the test dataset \n",
    "- Split it into mini-batches of rows \n",
    "- Convert the mini-batches to CSV string paylods (target variable is dropped from the dataset first)\n",
    "- Retrieve min-batch predictions by invoking the XGBoost Endpoint \n",
    "- Collect predictions and convert from the CSV output the model provides, into a NumPy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6db74c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, predictor, rows = 500): \n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) * 1))\n",
    "    predictions = ''\n",
    "    for array in split_array: \n",
    "        predictions = ','.join([predictions, predictor.predict(array).decode('utf-8')])\n",
    "        \n",
    "    return np.fromstring(predictions[1:], sep = ',')\n",
    "\n",
    "predictions = predict(test_data.drop(['Class'], axis = 1).to_numpy(), xgb_predictor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "453b0bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28440</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions    0.0  1.0\n",
       "actual                 \n",
       "0            28440    2\n",
       "1                8   31"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index = test_data.iloc[:,0], columns = np.round(predictions), rownames = ['actual'], colnames = ['predictions'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7701ee",
   "metadata": {},
   "source": [
    "Due to the randomized elements of the algorithm, results may vary. \n",
    "\n",
    "Of the 39 fraudsters, 31 of them have been correctly predicted (true positives). There is an incorrect prediction of 2 people as fraudsters (false-positive). There are also 8 cases of fraud that the model has not predicted as fraudulent (true-negative) which can have an impact in the real-world scenario. \n",
    "\n",
    "An important point here is that because of the np.round() function, a simple threshold of 0.5 is used. Predictions from XGBoost are continuous values between 0 and 1 and are forced into binary classes (as per the source). This cutoff can be adjusted, which might either result in the increase of false-positive or increase of true-positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203da369",
   "metadata": {},
   "source": [
    "## Automatic Model Tuning (AMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5b52c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {'eta': ContinuousParameter(0, 1), \n",
    "                        'min_child_weight': ContinuousParameter(1, 10),\n",
    "                        'alpha': ContinuousParameter(0, 2), \n",
    "                        'max_depth': IntegerParameter(1, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3ec5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'validation:auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec7440fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(xgb, objective_metric_name, hyperparameter_ranges, max_jobs = 9, max_parallel_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c9b3b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job ( \n",
    "HyperParameterTuningJobName = tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e357111",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed91012",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_predictor = tuner.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a12b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d9659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0766c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29e1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b90ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
